FROM nvcr.io/nvidia/l4t-jetpack:r36.4.0

# PyPI 镜像与 uv 网络容错
ENV UV_INDEX_URL=https://pypi.tuna.tsinghua.edu.cn/simple
ENV UV_EXTRA_INDEX_URL=https://mirrors.aliyun.com/pypi/simple
ENV UV_HTTP_TIMEOUT=300
ENV UV_HTTP_RETRIES=8
ENV UV_HTTP_CONCURRENCY=4

# 基础依赖 + Rust（给 SudachiPy 等构建用）
RUN set -eux; \
    mkdir -p /tmp && chmod 1777 /tmp; \
    apt-get update; \
    apt-get install -y --no-install-recommends \
        python3.10 python3-venv ca-certificates gnupg \
        rustc cargo build-essential pkg-config python3-dev \
        espeak-ng espeak-ng-data git libsndfile1 curl ffmpeg g++; \
    rm -rf /var/lib/apt/lists/*

# cargo 在国内网络用 CLI 拉取更稳
ENV CARGO_NET_GIT_FETCH_WITH_CLI=true

# espeak-ng 数据与 uv（脚本改为走镜像并使用 UV_UNMANAGED_INSTALL）
RUN set -eux; \
    mkdir -p /usr/share/espeak-ng-data; \
    ln -s /usr/lib/*/espeak-ng-data/* /usr/share/espeak-ng-data/ || true; \
    curl -LsSf https://astral.sh/uv/install.sh -o install.sh; \
    sed -i 's#https://github.com#https://gh-proxy.com/https://github.com#g' install.sh; \
    env UV_UNMANAGED_INSTALL="/usr/local" sh install.sh; \
    rm -f install.sh; \
    uv --version && uvx --version

# 非 root 运行
RUN useradd -m -u 1001 appuser && mkdir -p /app/api/src/models/v1_0 && chown -R appuser:appuser /app
USER appuser
WORKDIR /app

# 先同步除 torch 以外的依赖（l4t 组现在不再包含 torch）
COPY --chown=appuser:appuser pyproject.toml ./pyproject.toml
RUN uv venv --python 3.10 && uv sync --extra l4t --no-cache

# Jetson/L4T 专用：用 pip 安装 NVIDIA 官方 PyTorch wheel（先 pin numpy 1.26.1）
# 参考：NVIDIA Jetson PyTorch 安装指引（建议先装 numpy==1.26.1，再 pip 安装对应 JP 目录的 wheel） [oai_citation:1‡NVIDIA Docs](https://docs.nvidia.com/deeplearning/frameworks/install-pytorch-jetson-platform/index.html?utm_source=chatgpt.com)
RUN set -eux; \
    . .venv/bin/activate; \
    python -m pip install --no-cache-dir "numpy==1.26.1"; \
    python -m pip install --no-cache-dir \
      https://developer.download.nvidia.com/compute/redist/jp/v61/pytorch/torch-2.5.0a0+872d972e41.nv24.08.17622132-cp310-cp310-linux_aarch64.whl

# 其余项目文件
COPY --chown=appuser:appuser api ./api
COPY --chown=appuser:appuser web ./web
COPY --chown=appuser:appuser docker/scripts/ ./
RUN chmod +x ./entrypoint.sh

# 运行环境
ENV PATH="/app/.venv/bin:$PATH" \
    PYTHONUNBUFFERED=1 \
    PYTHONPATH=/app:/app/api \
    UV_LINK_MODE=copy \
    USE_GPU=true \
    PHONEMIZER_ESPEAK_PATH=/usr/bin \
    PHONEMIZER_ESPEAK_DATA=/usr/share/espeak-ng-data \
    ESPEAK_DATA_PATH=/usr/share/espeak-ng-data \
    DEVICE="gpu" \
    DOWNLOAD_MODEL=true

#（可选）首次构建时下载模型
RUN if [ "$DOWNLOAD_MODEL" = "true" ]; then \
      python download_model.py --output api/src/models/v1_0; \
    fi

CMD ["./entrypoint.sh"]